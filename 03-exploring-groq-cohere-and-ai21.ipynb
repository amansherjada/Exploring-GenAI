{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing API Keys for Groq, Cohere, and AI21\n---\n\n![Image](https://i.ibb.co/Hz7JkBQ/DALL-E-2025-01-22-10-48-09-A-visually-striking-futuristic-technology-themed-environment-showcasing-t.webp)","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"AI21_API_KEY\")\nsecret_value_1 = user_secrets.get_secret(\"COHERE_API_KEY\")\nsecret_value_2 = user_secrets.get_secret(\"GROQ_API_KEY\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T04:59:38.977979Z","iopub.execute_input":"2025-01-22T04:59:38.978395Z","iopub.status.idle":"2025-01-22T04:59:39.893424Z","shell.execute_reply.started":"2025-01-22T04:59:38.978362Z","shell.execute_reply":"2025-01-22T04:59:39.892326Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# [Groq](https://groq.com/) Example\n---","metadata":{}},{"cell_type":"code","source":"pip install groq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T03:56:05.361252Z","iopub.execute_input":"2025-01-22T03:56:05.361607Z","iopub.status.idle":"2025-01-22T03:56:11.342636Z","shell.execute_reply.started":"2025-01-22T03:56:05.361578Z","shell.execute_reply":"2025-01-22T03:56:11.341253Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting groq\n  Downloading groq-0.15.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\nDownloading groq-0.15.0-py3-none-any.whl (109 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: groq\nSuccessfully installed groq-0.15.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from groq import Groq\n\nclient = Groq(\n    api_key=secret_value_2,\n)\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"What is Groq?\",\n        }\n    ],\n    model=\"llama-3.3-70b-versatile\",\n)\n\nprint(chat_completion.choices[0].message.content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T04:44:28.672670Z","iopub.execute_input":"2025-01-22T04:44:28.673025Z","iopub.status.idle":"2025-01-22T04:44:29.956273Z","shell.execute_reply.started":"2025-01-22T04:44:28.672977Z","shell.execute_reply":"2025-01-22T04:44:29.955276Z"}},"outputs":[{"name":"stdout","text":"Groq is a technology company that specializes in the development of artificial intelligence (AI) and machine learning (ML) hardware and software solutions. However, I couldn't find much information on a well-known company with that name. \n\nIt's possible that Groq is a lesser-known or emerging company, or it could be a concept or product that hasn't gained widespread attention yet. If you have more context or details about Groq, I'd be happy to try and help you better. \n\nThat being said, I did find some information on a company called Groq that was founded in 2016 and was focused on developing AI and ML-specific hardware accelerators. The company's goal was to create high-performance, low-power chips that could accelerate AI and ML workloads. However, I couldn't find any recent updates on the company's status or activities.\n\nIf you have any more information or clarification about Groq, I'd be happy to try and help you further.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# [Cohere](https://cohere.com/) Example\n---","metadata":{}},{"cell_type":"code","source":"pip install cohere","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T04:43:31.961169Z","iopub.execute_input":"2025-01-22T04:43:31.961647Z","iopub.status.idle":"2025-01-22T04:43:38.251250Z","shell.execute_reply.started":"2025-01-22T04:43:31.961620Z","shell.execute_reply":"2025-01-22T04:43:38.249934Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting cohere\n  Downloading cohere-5.13.11-py3-none-any.whl.metadata (3.4 kB)\nCollecting fastavro<2.0.0,>=1.9.4 (from cohere)\n  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.1)\nCollecting httpx-sse==0.4.0 (from cohere)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\nRequirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\nRequirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.21.0)\nCollecting types-requests<3.0.0,>=2.0.0 (from cohere)\n  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.12.14)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.27.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\nDownloading cohere-5.13.11-py3-none-any.whl (252 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\nInstalling collected packages: types-requests, httpx-sse, fastavro, cohere\nSuccessfully installed cohere-5.13.11 fastavro-1.10.0 httpx-sse-0.4.0 types-requests-2.32.0.20241016\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import cohere\n\nco = cohere.ClientV2(secret_value_1)\nresponse = co.chat(\n    model=\"command-r-plus\", \n    messages=[{\"role\": \"user\", \"content\": \"What is Cohere?\"}]\n)\n\nprint(response.message.content[0].text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T04:49:05.513791Z","iopub.execute_input":"2025-01-22T04:49:05.514195Z","iopub.status.idle":"2025-01-22T04:49:10.600513Z","shell.execute_reply.started":"2025-01-22T04:49:05.514166Z","shell.execute_reply":"2025-01-22T04:49:10.599364Z"}},"outputs":[{"name":"stdout","text":"Cohere is a Canadian startup that provides a large language model (LLM) platform that empowers developers to build applications that can understand and generate human-like language. The company was founded in 2019 by Aidan Gomez, Nick Frosst, and Ivan Zhang, who are experts in machine learning and artificial intelligence.\n\nThe core product of Cohere is its LLM API, which allows developers to integrate advanced language processing capabilities into their applications without requiring extensive expertise in natural language processing (NLP) or machine learning. The API offers a range of functionalities, including text generation, summarization, question-answering, and sentiment analysis, among others.\n\nOne of the key strengths of Cohere's platform is its focus on simplicity and ease of use. The company aims to democratize access to powerful language models and make it accessible to a wide range of developers and businesses. The API is designed to be flexible and scalable, allowing users to customize and adapt it to their specific needs.\n\nCohere's LLMs are trained on massive amounts of text data and are capable of understanding and generating human-like language in a variety of contexts. The company has also placed a strong emphasis on responsible AI practices, including transparency, fairness, and accountability, to ensure that its technology is used ethically and responsibly.\n\nOverall, Cohere offers a powerful and flexible LLM platform that has the potential to revolutionize how developers build language-based applications and enable a new generation of AI-powered products and services.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# [AI21](https://www.ai21.com/) Example\n---","metadata":{}},{"cell_type":"code","source":"pip install ai21","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T04:58:16.961795Z","iopub.execute_input":"2025-01-22T04:58:16.962186Z","iopub.status.idle":"2025-01-22T04:58:23.130173Z","shell.execute_reply.started":"2025-01-22T04:58:16.962162Z","shell.execute_reply":"2025-01-22T04:58:23.129059Z"},"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"collapsed":true},"outputs":[{"name":"stdout","text":"Collecting ai21\n  Downloading ai21-3.0.1-py3-none-any.whl.metadata (21 kB)\nCollecting ai21-tokenizer<1.0.0,>=0.12.0 (from ai21)\n  Downloading ai21_tokenizer-0.12.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting httpx<0.28.0,>=0.27.0 (from ai21)\n  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: pydantic<3.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from ai21) (2.10.3)\nCollecting tenacity<9.0.0,>=8.3.0 (from ai21)\n  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from ai21) (4.12.2)\nCollecting anyio<5.0.0,>=4.4.0 (from ai21-tokenizer<1.0.0,>=0.12.0->ai21)\n  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: sentencepiece<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ai21-tokenizer<1.0.0,>=0.12.0->ai21) (0.2.0)\nRequirement already satisfied: tokenizers<1.0.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from ai21-tokenizer<1.0.0,>=0.12.0->ai21) (0.21.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21) (2024.12.14)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21) (3.10)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ai21) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=1.9.0->ai21) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=1.9.0->ai21) (2.27.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.4.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (1.2.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (0.27.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (4.67.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (3.4.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21) (2.2.3)\nDownloading ai21-3.0.1-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ai21_tokenizer-0.12.0-py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\nDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tenacity, anyio, httpx, ai21-tokenizer, ai21\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 9.0.0\n    Uninstalling tenacity-9.0.0:\n      Successfully uninstalled tenacity-9.0.0\n  Attempting uninstall: anyio\n    Found existing installation: anyio 3.7.1\n    Uninstalling anyio-3.7.1:\n      Successfully uninstalled anyio-3.7.1\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.28.1\n    Uninstalling httpx-0.28.1:\n      Successfully uninstalled httpx-0.28.1\nSuccessfully installed ai21-3.0.1 ai21-tokenizer-0.12.0 anyio-4.8.0 httpx-0.27.2 tenacity-8.5.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from ai21 import AI21Client\nfrom ai21.models.chat import ChatMessage\n\nmessages = [ChatMessage(content=\"What is AI21 Lab's Jamba? \", role=\"user\")]\n\nclient = AI21Client(api_key=secret_value_0)\n\nresponse = client.chat.completions.create(\n  messages=messages,\n  model=\"jamba-1.5-mini\",\n  stream=True\n)\n\nfor chunk in response:\n  print(chunk.choices[0].delta.content, end=\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T05:02:27.799898Z","iopub.execute_input":"2025-01-22T05:02:27.800256Z","iopub.status.idle":"2025-01-22T05:02:28.652112Z","shell.execute_reply.started":"2025-01-22T05:02:27.800207Z","shell.execute_reply":"2025-01-22T05:02:28.651324Z"}},"outputs":[{"name":"stderr","text":"[2025-01-22 05:02:28 - httpx - INFO] HTTP Request: POST https://api.ai21.com/studio/v1/chat/completions \"HTTP/1.1 200 OK\"\n","output_type":"stream"},{"name":"stdout","text":"NoneAI21 Lab's Jamba is a large language model designed to assist users in a variety of tasks, including answering questions, generating text, and more. It is built to be helpful and professional, ensuring that the responses are accurate and relevant. Jamba is capable of understanding and generating human-like text, making it a versatile tool for various applications.","output_type":"stream"}],"execution_count":20}]}