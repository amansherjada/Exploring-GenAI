{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **[HuggingFace Pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines)**\n\nHugging Face Pipelines are **high-level tools** that make it super easy to use pre-trained machine learning models for common tasks like text generation, translation, summarization, question answering, image classification, and more. \n\nThey take care of all the complex stuff behind the scenes (like tokenizing input, processing it through the model, and decoding the output), so you can focus on solving your problem with just a few lines of code.\n\n---\n\n### **How Pipelines Work:**\nImagine you have a robot assistant, and all you have to do is:\n1. Tell the robot what kind of task you want it to do (e.g., generate text, translate languages, etc.).\n2. Provide some input (e.g., a sentence to complete or a question to answer).\n3. Get the result (e.g., the generated text or the answer).\n\nThe robot knows which tools (models) to use, how to prepare the input for those tools, and how to give you the results in a readable way.\n\n---\n\n### **Key Features of Hugging Face Pipelines:**\n1. **Pre-trained Models:** Use ready-made models trained on massive datasets for tasks like:\n   - Text generation\n   - Sentiment analysis\n   - Question answering\n   - Image classification\n2. **Ease of Use:** Simple one-liner to perform tasks, no need to write complex model loading or preprocessing code.\n3. **Flexibility:** You can use a default model or specify your own custom model.\n4. **Broad Task Support:** Covers a wide range of NLP, vision, and audio tasks.\n\n---\n\n### **Example of Hugging Face Pipelines:**\n```python\nfrom transformers import pipeline\n\n# Load a pipeline for text generation\ntext_generator = pipeline(\"text-generation\", model=\"gpt2\")\n\n# Generate text\nresult = text_generator(\"Once upon a time,\")[0]['generated_text']\nprint(result)\n```\n\n---\n\n### **Why Use Hugging Face Pipelines?**\n1. **Beginner-Friendly:** Great for people who are new to machine learning.\n2. **Time-Saving:** No need to worry about data preprocessing, tokenization, or decoding results.\n3. **Powerful Models:** You can leverage state-of-the-art models without worrying about their implementation.\n\nHugging Face Pipelines are like an \"all-in-one\" toolkit that helps you get results quickly and effectively without deep knowledge of the underlying machine learning processes.","metadata":{}},{"cell_type":"code","source":"pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:48:14.854504Z","iopub.execute_input":"2025-01-22T08:48:14.854784Z","iopub.status.idle":"2025-01-22T08:48:21.173074Z","shell.execute_reply.started":"2025-01-22T08:48:14.854763Z","shell.execute_reply":"2025-01-22T08:48:21.171832Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:52:04.837615Z","iopub.execute_input":"2025-01-22T08:52:04.837969Z","iopub.status.idle":"2025-01-22T08:52:05.272110Z","shell.execute_reply.started":"2025-01-22T08:52:04.837937Z","shell.execute_reply":"2025-01-22T08:52:05.271169Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:57:32.809330Z","iopub.execute_input":"2025-01-22T08:57:32.809671Z","iopub.status.idle":"2025-01-22T08:57:33.057370Z","shell.execute_reply.started":"2025-01-22T08:57:32.809652Z","shell.execute_reply":"2025-01-22T08:57:33.056571Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# [TextGenerationPipeline](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TextGenerationPipeline)","metadata":{}},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:57:36.597305Z","iopub.execute_input":"2025-01-22T08:57:36.597624Z","iopub.status.idle":"2025-01-22T08:58:43.790984Z","shell.execute_reply.started":"2025-01-22T08:57:36.597605Z","shell.execute_reply":"2025-01-22T08:58:43.789718Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d50a797644bb46c381d9249fe5fb6b34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff832c5be5a349f88add0a87c1351334"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44bb3372f64d47b181214eae8df76fd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2070e3bd992c47d08faa4801040c0d11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd3988954c1a431cb3ef30887ac6d9f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b83c57080254aa6890eac0e0ce53ee2"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"result = pipe(\"Once upon a time,\")\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T08:59:06.530225Z","iopub.execute_input":"2025-01-22T08:59:06.531301Z","iopub.status.idle":"2025-01-22T08:59:13.482262Z","shell.execute_reply.started":"2025-01-22T08:59:06.531264Z","shell.execute_reply":"2025-01-22T08:59:13.481120Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[{'generated_text': 'Once upon a time, I was in a meeting with a colleague who was describing a problem he was having with a piece of'}]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(result[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T09:02:03.371265Z","iopub.execute_input":"2025-01-22T09:02:03.371675Z","iopub.status.idle":"2025-01-22T09:02:03.376843Z","shell.execute_reply.started":"2025-01-22T09:02:03.371647Z","shell.execute_reply":"2025-01-22T09:02:03.375874Z"}},"outputs":[{"name":"stdout","text":"Once upon a time, I was in a meeting with a colleague who was describing a problem he was having with a piece of\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"result2 = pipe(\"Once upon a time,\", num_return_sequences=4)\nprint(result2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T09:13:21.236422Z","iopub.execute_input":"2025-01-22T09:13:21.236940Z","iopub.status.idle":"2025-01-22T09:13:43.293402Z","shell.execute_reply.started":"2025-01-22T09:13:21.236906Z","shell.execute_reply":"2025-01-22T09:13:43.291976Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[{'generated_text': 'Once upon a time, I was a very happy and healthy young woman. I was a teacher, a wife, and a'}, {'generated_text': 'Once upon a time, I was a college student. I was a college student in the year 2000. I was'}, {'generated_text': 'Once upon a time, there was a young man who was very interested in the world of science. He wanted to learn as'}, {'generated_text': 'Once upon a time, there was a man who had a dream. He dreamed of having a business that would be successful.'}]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(result2[0]['generated_text'])\nprint(result2[1]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T09:15:14.721163Z","iopub.execute_input":"2025-01-22T09:15:14.721645Z","iopub.status.idle":"2025-01-22T09:15:14.728248Z","shell.execute_reply.started":"2025-01-22T09:15:14.721623Z","shell.execute_reply":"2025-01-22T09:15:14.727080Z"}},"outputs":[{"name":"stdout","text":"Once upon a time, I was a very happy and healthy young woman. I was a teacher, a wife, and a\nOnce upon a time, I was a college student. I was a college student in the year 2000. I was\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"result3 = pipe(\"Once upon a time,\", return_full_text=True)\nprint(result3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T09:16:39.539725Z","iopub.execute_input":"2025-01-22T09:16:39.540185Z","iopub.status.idle":"2025-01-22T09:16:46.376987Z","shell.execute_reply.started":"2025-01-22T09:16:39.540147Z","shell.execute_reply":"2025-01-22T09:16:46.375718Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[{'generated_text': 'Once upon a time, there was a young man named John. He was a successful businessman, and he had a beautiful wife'}]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(result3[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T09:18:05.447325Z","iopub.execute_input":"2025-01-22T09:18:05.447683Z","iopub.status.idle":"2025-01-22T09:18:05.452987Z","shell.execute_reply.started":"2025-01-22T09:18:05.447663Z","shell.execute_reply":"2025-01-22T09:18:05.451787Z"}},"outputs":[{"name":"stdout","text":"Once upon a time, there was a young man named John. He was a successful businessman, and he had a beautiful wife\n","output_type":"stream"}],"execution_count":17}]}